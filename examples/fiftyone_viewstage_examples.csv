query,stages,added_by,media_type,geo,text_sim,image_sim,eval,metadata,label_type,,,,,,,,,,,,,,,,,
"Create a view excluding samples whose `my_field` field have values in ['a', 'b', 'e', '1']","[exclude_by('my_field', ['a', 'b', 'e', '1'])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"remove samples with 1, 3, 5, 7, or 9 in 'num_predictions' field","[exclude_by('num_predictions', [1, 3, 5, 7, 9])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Exclude the `field_to_omit` field from all samples,[exclude_fields('field_to_omit')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
remove the `mood` attribute from the 'health' field,[exclude_fields('health.mood')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
omit all predictions,[exclude_fields('predictions')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
exclude fields 'fieldA' and 'fieldB',"[exclude_fields(['fieldA', 'fieldB'])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Exclude labels with tag 'test',[exclude_labels(tags='test')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
don't show predictions with the 'old' tag,"[exclude_labels(tags=['old'], fields = ['predictions'])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Exclude labels with red or blue tags,"[exclude_labels(tags=['red', 'blue'])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Don't show me the fifth and sixth samples,"[exclude([dataset.skip(4).first().id, dataset.skip(5).first().id])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
exclude the 8th image,[exclude([dataset.skip(7).first().id)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
image with model1 confidences,[exists('model1.confidence')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only show samples with field 'my_field',[exists('my_field')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that have a value in their `predictions`,[exists('predictions')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
samples that do NOT have a value in some_field,"[exists('some_field', False)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"filter the 'my_field' field for negative values, but show me all images, even those that aren't matches","[filter_field('my_field', F() < 0), only_matches = False]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples whose `numeric_field` value is positive,"[filter_field('numeric_field', F() > 0)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Just show classifications in the `pred_classif` field with label 'mug',"[filter_field('pred_classif', F('label') == 'mug')]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"i only want to see the detections with a validation tag, and only show me the images that have detections matching this filter","[filter_field('tags', F().contains('validation'), only_matches = True)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Label contains string 'be',"[filter_labels('ground_truth', F('label').contains_str('be'))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
filter classifications in the 'my_model' field down to those with label hat or hair,"[filter_labels('my_model', F('label').is_in(['hat', 'hair']))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Predictions with confidence > 0.95,"[filter_labels('predictions', F('confidence') > 0.95)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
resnet predictions with 70+% confidence,"[filter_labels('resnet', F('confidence') > 0.75)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Within 5km of Times Square,"[geo_near([-73.9855, 40.7580], max_distance=5000)]",Jacob,all,TRUE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Less than a mile from disney world,"[geo_near([-81.5707, 28.3772], max_distance=1609.34)]",Jacob,all,TRUE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
At least 100 kilometers away from Beijing,"[geo_near([116.4725, 39.9523, min_distance=100000)]",Jacob,all,TRUE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
first 100 samples,[limit(100)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Limit the view to 35,[limit(35)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that contain predictions with > 99% confidence,"[match_labels(filter=F('confidence') > 0.99, fields='predictions')]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that contain labels with ids hofwihuf or abxjhbvcie,"[match_labels(ids=[hofwihuf, abxjhbvcie])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
get samples with labels with the 'test tag,"[match_labels(tags='test')]
",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that have the 'mistake' tag,[match_tags('mistake')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that do not have the 'validation' tag,"[match_tags('validation', bool=False)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Union of the validation and test splits,"[match_tags(('validation', 'test'))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that do not have the 'A' or 'B' tags,"[match_tags(['A', 'B'], bool=False)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that have the 'test' and 'train' tags,"[match_tags(['test', 'train'], all=True)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that have the 'test' or 'train' tags,"[match_tags(['test', 'train'])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that do not have the 'this' and 'that' tags,"[match_tags(['this', 'that'], bool=False, all=True)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Images that only contain dogs,[match(F('ground_truth.detections.label').is_subset(['dog']))],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Get samples that do NOT have a value for `new_field`,[match(~F('new_field').exists())],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"Only contains samples with `uniqueness` in [0.25, 0.75]",[match(abs(F('uniqueness') - 0.5) < 0.25)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Samples with odd seconds,[match(F('created_at').second() % 2 != 0)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
view of samples with non-None 'data_field',[match(F('data_field').type() != 'null')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
On the 24th of the month,[match(F('date').day_of_month() == 24)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
On even day of the week,[match(F('date').day_of_week() % 2 == 0)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
On the 268th day of the year,[match(F('date').day_of_year() == 268)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
With minute not equal to 0,[match(F('date').minute() != 0)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
In september,[match(F('date').month() == 9)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
In the 38th week of the year,[match(F('date').week() == 38)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
2022,[match(F('date').year() == 2022)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Samples with even milliseconds for the 'event_time' field,[match(F('event_time').millisecond() % 2 == 0)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
a view of all samples with arccos('field_to_apply_to') less than 0.2,[match(F('field_to_apply_to').arccos() < 0.2)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Get samples whose images are JPEGs or PNGs,"[match(F('filepath').ends_with(('.jpg', '.png')))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Filepath ends with '10.jpg' or '10.png',"[match(F('filepath').ends_with(('10.jpg', '10.png'))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
get the filepaths that are strings,[match(F('filepath').is_string())],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Filepath contains “088” and is JPEG,[match(F('filepath').re_match('088*.jpg'))],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Filepath starts with '/Users',[match(F('filepath').starts_with('/Users'))],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
images where sinh of my_numeric_field is greater than 0.6,[match(F('my_numeric_field').sinh() > 0.6)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Uniqueness > 0.9,[match(F('uniqueness') > 0.9)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Create view that only contains samples with uniqueness = None,[match(F('uniqueness').is_null())],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples whose `weather` field is 'sunny',[match(F('weather').label == 'sunny')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"Create a view containing samples whose `str` field have the given: ['1', '51', '11', '41', '21', '31'], in order","[select_by('str', ['1', '51', '11', '41', '21', '31'], ordered=True)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"Create a view containing samples whose `int` field have 1, 51, or 33","[select_by('int', [1, 51, 33])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only show 'mistakenness',[select_fields('mistakenness')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Include only the `uniqueness` field,[select_fields('uniqueness')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Get all labels with the test tag,[select_labels(tags='test')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Map numeric `my_field` values to 1 and null values to 0,"[set_field('my_field', F('my_field').type().cases(LEFTBRACKET'double': 1, 'null': 0RIGHTBRACKET))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Replace all values of the `uniqueness` field that are less than 0.5 with `None`,"[set_field('uniqueness', (F('uniqueness') >= 0.5).if_else(F('uniqueness'), None))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Round `uniqueness` values to either 0.25 or 0.75,"[set_field('uniqueness', F('uniqueness').switch(LEFTBRACKET(0.0 < F()) & (F() <= 0.5): 0.25, (0.5 < F()) & (F() <= 1.0): 0.75RIGHTBRACKET))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
exclude the tag 'my_tag',"[set_field('tags', F('tags').difference(['my_tag']))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
create a view that only shows the 'cvat' and 'labelbox' tags,"[set_field('tags', F('tags').intersection(['cvat', 'labelbox']))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
select the train and test tags,"[set_field('tags', F('tags').intersection(['train', 'test']))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Convert all tags to lowercase,"[set_field('tags', F('tags').map(F().lower()))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me random samples,[shuffle()],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
shuffle,[shuffle()],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
skip the first 10 samples,[skip(10)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
don't show me the first 30,[skip(30)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Sort by filepath,[sort_by('filepath')],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
ten least wrong predictions,"[sort_by('mistakenness', reverse=False), limit(10)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
10 most “wrong” predictions,"[sort_by('mistakenness', reverse=True), limit(10)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
15 most wrong predictions,"[sort_by('mistakenness', reverse=True), limit(15)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
sort samples by 'numeric_field' in ascending order,"[sort_by('numeric_field', reverse=False)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
10 most unique images,"[sort_by('uniqueness'), limit(10)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
20 least unique samples,"[sort_by('my_uniqueness_fields', reverse = True), limit(20)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
take 10 random samples from the dataset with seed=51,"[take(10, seed=51)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Take two random samples from the dataset,[take(2)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me 50 random samples,[take(50)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
shuffle the samples and take the last 4,"[shuffle(), skip(-4)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
last 50 samples,[skip(-50)],Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"add a new tag ""xyz"" to each sample","[set_field(""tags"", F('tags').append('xyz'))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
delete first tag from each image,"[set_field(""tags"", F('tags')[1:])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
sort samples by number of tags,"[sort_by(F(""tags"").length())]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me samples with more than one tag,"[match(F(""tags"").length() > 1)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
samples 40-70,"[skip(40), limit(30)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
I want to see the samples whose predicted price is > 60,"[match(F(""predicted_price.value"") < 60.)]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Find my 8 biggest flaws,"[sort_by(""""mistakenness"""", reverse=True), limit(8)]",Leila,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Sort images by hardness,"[sort_by(""""hardness"""", reverse=True)]",Leila,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"Find all samples where the filepath contains ""08"" or ""09""","[match(F(""filepath"").contains_str([""08"", ""09""])]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"Retrieve any images whose filepath has ""ab"" and ""xy""","[match(F(""filepath"").contains_str([""ab""]) & F(""filepath"").contains_str([""xy""]))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"Show me just the labels that have the tag ""tagA"" but don't have tag ""tagB""","[filter_labels(""predictions"", F(""tags"").contains(""tagA"") & ~F(""tags"").contains(""tagB""))]",Jacob,all,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Exclude frame with id 'kbdskajdvfef',[exclude_frames(['kbdskajdvfef'])],Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
clip view with one clip per meeting,"[filter_labels('events', F('label') == 'meeting'), to_clips('events')]",Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
Create a clips view that contains one clip for each contiguous segment that contains at least one road sign in every frame,"[filter_labels('frames.detections', F('label') == 'road sign'), to_clips('frames.detections')]",Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
Create a trajectories view for the vehicles in the dataset,"[filter_labels('frames.detections', F('label') == 'vehicle'),
 to_trajectories('frames.detections')]",Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
show 'vehicle' detections in the 'detections' field,"[filter_labels('frames.detections', F('label') == 'vehicle')]",Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
"Create a frames view that only contains frames with at least 10 objects, sampled at a maximum frame rate of 1fps","[match_frames(F('detections.detections').length() > 10), to_frames(max_fps=1)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
Frames with at least 10 detections,[match_frames(F('detections.detections').length() > 10)],Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
select just the first and last frames in the first sample,"[select_frames([dataset.first().frames.first().id, dataset.last().frames.last().id])]",Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
Create a clips view with one clip per event,[to_clips('events')],Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
Create a clips view that contains one clip for each contiguous segment that contains at least two road signs in every frame,[to_clips(F('detections.detections').filter(F('label') == 'road sign').length() >= 2)],Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
frames with set filepath,[to_frames()],Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
Create a frame patches view,"[to_frames(sample_frames=True), to_patches('detections')]",Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
Frames view,[to_frames(sample_frames=True)],Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
sort by width,"[sort_by(F(""metadata.frame_width""))]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
"sort by frame width, with widest frames first","[sort_by(F(""metadata.frame_width""), reverse = True)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
sort by height of the videos,"[sort_by(F(""metadata.frame_height""))]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
sort video by size,"[sort_by(F(""metadata.size_bytes""))]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
10 largest videos,"[sort_by(F(""metadata.size_bytes""), reverse = True), limit(10)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
videos with frame rate higher than 30 fps,"[match(F(""metadata.frame_rate"") > 30)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
"sort the movies by frame rate, with fastest first","[sort_by(F(""metadata.frame_rate""), reverse = True)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
videos that are wider than they are tall,"[match(F(""metadata.frame_width"")>F(""metadata.frame_height""))]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
videos that are approximately square,"[match(abs(F(""metadata.frame_width"")-F(""metadata.frame_height""))<1)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
all the videos whose frames are at least 1.5 times as tall as they are wide,"[match(1.5*F(""metadata.frame_width"")<F(""metadata.frame_height""))]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,TRUE
retrieve all movies that have between 50 and 100 frames,"[match(F(""metadata.total_frame_count"") > 50), match(F(""metadata.total_frame_count"") < 50)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,FALSE,FALSE
show me the videos with more than 75 frames,"[match(F(""metadata.total_frame_count"") > 75)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,TRUE,FALSE
only show videos that are longer than 4 seconds,"[match(F(""metadata.duration"") > 4)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,TRUE,FALSE
give me the 10 longest videos,"[sort_by(F(""metadata.duration""), reverse=True), limit(10)]",Jacob,video,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,TRUE,FALSE
"Restrict to frames which have field ""my_field""","[dataset.match_frames(F(""my_field""))]",Jacob,video,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,video,FALSE,FALSE,FALSE,TRUE,FALSE
Sort by the total number of false positives across all frames in the video,"[sort_by(""EVAL_KEY_fp"")]",Jacob,video,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,video,FALSE,TRUE,FALSE,FALSE,FALSE
Give me all vids with at least 1k total false negatives,"[match(F(""EVAL_KEY_fn"")>1000)]",Jacob,video,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
show all frames with more than 5 TP predictions,"[match_frames(F(""EVAL_KEY_tp"") > 5)]",Jacob,video,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
any frames with 2 or more FPs and 3 or more FNs,"[match_frames(F(""EVAL_KEY_fp"") > 2), match_frames(F(""EVAL_KEY_fn"") > 3)]",Jacob,video,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Give me the 5 frames that look most like it is raining out,"[to_frames(), sort_by_similarity(""rainy"", brain_key=""TEXT_SIM_KEY"", k = 5)]",Jacob,video,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include samples that have prediction confidences,[exists('predictions.confidence')],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
Only include classifications in the `predictions` field whose label is camel,"[filter_field('predictions', F('label') == 'camel')]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
Remove tags from samples that don't include the 'validation' tag,"[filter_field('tags', F().contains('validation'))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include keypoints in the `predictions` field whose `confidence` is greater than 0.9,"[filter_keypoints('predictions', filter=F('confidence') > 0.9)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
keypoints in the `predictions` field with label 'left eye' or 'right eye',"[filter_keypoints('predictions', labels=['left eye', 'right eye'])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
Only include samples whose ground truth `label` is 'slug' or 'conch',"[filter_labels('ground_truth', (F('label') == 'slug') | (F('label') == 'conch'))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
Show me images that contain a railroad,[match(F('ground_truth.detections.label').contains(['railroad'])],Eric,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Only show predictions with label 'cat' and confidence > 0.9,"[filter_labels('predictions', (F('label') == 'cat') & (F('confidence') > 0.9))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Discard all predictions with confidence below 0.3,"[filter_labels('predictions', F('confidence') > 0.3, only_matches=False)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include classifications in the `predictions` field whose label is 'frog' or 'turtle',"[filter_labels('predictions', F('label').is_in(['frog', 'turtle']))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only include polylines in the `faster-rcnn` field whose `label` is 'lane',"[filter_labels('faster-rcnn', F('label') == 'lane')]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Only contains predictions whose bounding boxes' upper left corner is a Manhattan distance of at least 1 from the origin,"[filter_labels('predictions, F('bounding_box')[0] + F('bounding_box')[1] > 1)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
"Create a view that only contains predictions whose bounding boxes
have area < 0.2 with confidence > 0.9, and only include samples with
at least 15 such objects","[filter_labels('predictions', (bbox_area < 0.2) & (F('confidence') > 0.9)), match(F('predictions.detections').length() > 15)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Only include detections in the `predictions` field whose bounding box is smaller than 0.2,"[filter_labels('predictions', F('bounding_box')[2] * F('bounding_box')[3] < 0.2)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Only include polylines in the `predictions` field that are filled,"[filter_labels('predictions', F('filled') == True)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,polyline,,,,,,,,,,,,,,,,,
Only include keypoints in the `predictions` field whose `label` is 'house',"[filter_labels('predictions', F('label') == 'house')]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
Only include keypoints in the `predictions` field with less than four points,"[filter_labels('predictions', F('points').length() < 4)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
Only include polylines in the `fine-tuned` field with at least 3 vertices,"[filter_labels('predictions', F('points').map(F().length()).sum() >= 3)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,polyline,,,,,,,,,,,,,,,,,
limit 'ground_truth' detections to the first four,"[limit_labels('ground_truth', 4)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Only include the first detection in the `predictions` field of each sample,"[limit_labels('predictions', 1)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
map the cat and dog animal labels to pet and shark to wild,"[map_labels('animal', LEFTBRACKET'cat': 'pet', 'dog': 'pet', 'shark':'wild'RIGHTBRACKET)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
10 most likely annotation mistakes in training set,"[match_tags('train'), sort_by('mistakenness, reverse=True), limit(10)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Images that do not contain giraffes,[match(~F('ground_truth.detections.label').contains('giraffe'))],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
At least one dog,[match(F('ground_truth.detections.label').contains('dog'))],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
the first 30 samples with a plant,"[match(F('ground_truth.detections.label').contains('plant')), limit(30)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
10 random images with tables,"[match(F('ground_truth.detections.label').contains('table')), take(10)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Contains a rabbit and a tortoise prediction,"[match(F('predictions.detections.label').contains(['rabbit', 'tortoise'], all=True))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Contains a cat or mouse but not both,"[match(F('predictions.detections.label').contains(['cat', 'mouse']) & ~F('predictions.detections.label').contains(['cat', 'mouse'], all=True))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Only contains samples whose first and last prediction have the same label,"[match(F('predictions.detections')[0].apply(F('label')) == F('predictions.detections').reverse()[0].apply(F('label')))]
",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
unique and wrong,"[match(F('predictions.label') != F('ground_truth.label')), sort_by('uniqueness', reverse=True)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
fewer than 4 ground truth detections,[match(F('ground_truth.detections').length() < 10)],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Exactly 10 ground truth detections,[match(F('ground_truth.detections').length() == 10)],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
at least one object,[match(F('ground_truth.detections').length() > 0)],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Get samples whose ground truth `label` is NOT 'airplane',[match(F('ground_truth.label') != 'airplane')],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
Only include samples whose `predictions` field contains at least one object with area smaller than 0.2,[match(F('predictions.detections').filter(F('bounding_box')[2] * F('bounding_box')[3] < 0.2).length() > 0)],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Include only the `mood` attribute (and the default attributes) of each `Detection` in the `ground_truth` field,[select_fields('ground_truth.detections.mood')],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Only contains predictions whose bounding box center is a distance of at most 0.02 from the center of the image,"[select_fields('predictions'), filter_labels('predictions', ((F('bounding_box')[0] + 0.5 * F('bounding_box')[2] - 0.5) ** 2 +(F('bounding_box')[1] + 0.5 * F('bounding_box')[3] - 0.5) ** 2).sqrt() < 0.02)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Only contains predictions whose bounding boxes are within 1 pixel of being square,"[select_fields('predictions'), filter_labels('predictions', abs(F('$metadata.width') * F('bounding_box')[2] - F('$metadata.height') * F('bounding_box')[3]) <= 1)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,detection,,,,,,,,,,,,,,,,,
prediction bounding boxes with aspect ratio 2 or higher,"[select_fields('predictions'), filter_labels('predictions', F('$metadata.width')/F('$metadata.height') > 2)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Sort the model3 predictions in each sample of a dataset by `confidence`,"[set_field('model3.detections', F('detections').sort(key='confidence', numeric=True, reverse=True))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Lower bound all object confidences in the `predictions` field at 0.5,"[set_field('predictions.detections.confidence', F('confidence').max(0.5))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
"Replace the `label` attritubes of the objects in the `predictions` field according to the following rule: If the `label` starts with `b`, replace it with `b`. Otherwise, replace it with 'other'","[set_field('predictions.detections', F('detections').map(F().set_field('label', F('label').re_match('^b').if_else('b', 'other'))))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Truncate the `label` of each prediction to 3 characters,"[set_field('predictions.detections', F('detections').map(F().set_field('label', F('label').substr(count=3))))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Add a `min_area` property to the `predictions` field that records the minimum prediction area in that sample,"[set_field('predictions.min_area', F('detections').map(F('bounding_box')[2] * F('bounding_box')[3]).min())]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Add a `num_predictions` property to the `predictions` field that contains the number of objects in the field,"[set_field('predictions.num_predictions', F('$predictions.detections').length())]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Add a field to each `predictions` object that records the total confidence of the predictions,"[set_field('predictions.total_conf', F('detections').map(F('confidence')).sum())]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
a child holding a baseball bat,"[sort_by_similarity('a child holding a baseball bat', k = 15, brain_key = 'TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
kites high in the air,"[sort_by_similarity('kites high in the air', k=15, brain_key='TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"show me the 50 images that most resemble night-time, and return the similarity scores","[sort_by_similarity('night time', k=50, brain_key='TEXT_SIM_KEY', dist_field = True)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Sort samples by their similarity to sample with ID uigweuyf and give me the top 5,"[sort_by_similarity('uigweuyf', k=5, brain_key='IMAGE_SIM_KEY')]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me the 20 most similar imagages to the first image,"[sort_by_similarity(dataset.first().id, k=20, brain_key='IMAGE_SIM_KEY')]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
sort by similarity to the first image with a cat,"[sort_by_similarity(dataset.match(F('ground_truth.detections.label').contains('cat')).first().id, brain_key='IMAGE_SIM_KEY', k = 25)]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
sort by similarity to image 10,"[sort_by_similarity(dataset.skip(9).id, brain_key='IMAGE_SIM_KEY')]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"first sort images in descending order by number of detections. For samples with the same number of predictions, sort in ascending order by uniqueness","[sort_by([(F('predictions.detections').length(), -1),('uniqueness', 1),])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
sort predictions by number of detections,[sort_by( F('ground_truth.detections').length())],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Sort the samples in descending order by the number of detections in their `predictions` field whose bounding box area is less than 0.2,"[sort_by(F('predictions.detections').filter(F('bounding_box')[2] * F('bounding_box')[3] < 0.2).length(), reverse=True)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Create a patches view for the evaluation results,[to_evaluation_patches('EVAL_KEY')],Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Create a view containing the ground truth patches,[to_patches('ground_truth')],Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
Now extract patches for confident person predictions,"[filter_labels('predictions',(F('label') == 'person') & (F('confidence') > 0.9)), to_patches('predictions')]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
show me high confidence false positives,"[to_evaluation_patches('EVAL_KEY'), match(F('type')=='fp')]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
find false positives with confidence greater than 0.8,"[to_evaluation_patches('EVAL_KEY'), match(F('type')=='fp'), filter_labels('predictions',F('confidence')>0.8)]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
low confidence true positives,"[to_evaluation_patches('EVAL_KEY'), match(F('type')=='tp'), filter_labels('predictions',F('confidence')<0.4)]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
show me all false negatives,"[to_evaluation_patches('EVAL_KEY'), match(F('type')=='fn')]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
all false negatives involving cats,"[to_evaluation_patches('EVAL_KEY'), match(F('type')=='fn'), filter_labels('ground_truth',F('label')=='cat')]",,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
what are all the missed detections,"[to_evaluation_patches('EVAL_KEY'), match(F('type')=='fn')]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
find all the missed license plates,"[to_evaluation_patches('EVAL_KEY'), match(F('type')=='fn'), filter_labels('ground_truth',F('label')=='license plate')]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
show me all misclassified examples,[match(F('EVAL_KEY')==False)],Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
show me high confidence misclassifications,"[match(F('EVAL_KEY')==False), filter_labels('prediction',F('confidence')>0.8)]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
show me all misclassifications with a low confidence ,"[match(F('EVAL_KEY')==False), filter_labels('prediction',F('confidence')<0.4)]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
give me all vehicles that were misclassified ,"[match(F('EVAL_KEY')==False), filter_labels('ground_truth',F('label')=='vehicle')]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
find all cars that were misclassified as trucks,"[match(F('EVAL_KEY')==False), filter_labels('ground_truth',F('label')=='car'), filter_labels('prediction',F('label')=='truck')]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
all examples where the correct label is not in the top 5 predictions,[match(F('EVAL_KEY')==False)],Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
all false positives in the `predictions` field,"[filter_labels(""det_model"", F(""EVAL_KEY"") == 'fp')]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
show me all false positives in the open images evaluation,"[filter_labels(""predictions"", F(""EVAL_KEY"") == 'fp')]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
samples where `prediction1` and `prediction2` differ,[match(F('prediction1.label') != F('prediction2.label'))],Allen,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
images where `pred1` was wrong and `pred2` was right,"[match(F('EVAL_A_KEY')==True), match(F('EVAL_B_KEY')==False)]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
images where `prediction1` was wrong and `prediction2` was right,[match( (F('EVAL_A_KEY')==True) & (F('EVAL_B_KEY')==False))],Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
find all incorrect detections using evaluation with iou threshold 0.8,"[filter_labels(""detections"", F(""EVAL_KEY"").is_in(['fp', 'fn']))]",Allen,image,FALSE,FALSE,FALSE,TRUE,FALSE,detection,,,,,,,,,,,,,,,,,
show me the first 43 images with a dog or a horse,"[match( F('ground_truth.detections.label').contains(['dog', 'horse'])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
images with a table or a chair prediction,"[match( F('predictions.detections.label').contains(['table', 'chair'])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
"samples with a car, bicycle, or truck","[match( F('gt.detections.label').contains(['car', 'bike', 'truck'])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
any image with an Airplane or a Plane or a Helicopter prediction,"[match( F('predictions.detections.label').contains(['Airplane', 'Plane', 'Helicopter'])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
"sort images by the difference in number of detections between ""gt"" and ""model""","[sort_by(F(""model.detections.label"").length() - F(""gt.detections.label"").length(), reverse=False)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
images with more 'm1' detections than 'm2' detections,"[match(F(""m1.detections.label"").length() >= F(""m2.detections.label"").length())]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
all images with exactly 3 Lions and 1 Zebra,"[match(F(""ground_truth.detections"").filter(F(""label"") == ""Lion"").length() == 3), match(F(""ground_truth.detections"").filter(F(""label"") == ""Zebra"").length() == 1)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
images with a Shark prediction or a shark ground_truth,"[match_labels(filter=F(""label"") == ""Shark"", fields=""predictions""), match_labels(filter=F(""label"") == ""shark"", fields=""ground_truth"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
images with at least 10 people but no baseball bat,"[match(F(""ground_truth.detections"").filter(F(""label"") == ""person"").length() >= 10), match(F(""ground_truth.detections"").filter(F(""label"") == ""baseball bat"").length() == 0)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
sort by width,"[sort_by(F(""metadata.width""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
"sort by image width, with longest images first","[sort_by(F(""metadata.width""), reverse = True)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
sort by height,"[sort_by(F(""metadata.height""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
sort images by size,"[sort_by(F(""metadata.size_bytes""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
10 largest images,"[sort_by(F(""metadata.size_bytes""), reverse = True), limit(10)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
images that don't have 3 color channels,"[match(F(""metadata.num_channels"") != 3)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
images that are wider than they are tall,"[match(F(""metadata.width"")>F(""metadata.height""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
images that are approximately square,"[match(abs(F(""metadata.width"")-F(""metadata.height""))<1)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
all the images that are at least 1.5 times as tall as they are wide,"[match(1.5*F(""metadata.width"")<F(""metadata.height""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
only show me the keypoints on the left side of the images,"[filter_labels(""points"", F(""points"")[0][0]<0.5)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
keypoints in the 'face_points' field on the bottom of the image,"[filter_labels(""points"", F(""points"")[0][1]<0.5)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
just the human-generated point labels,"[filter_labels(""points"", F(""source"") == ""ih"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
positive keypoints,"[filter_labels(""points"", F(""estimated_yes_no"") == ""yes"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
positive example keypoints for the label Sky,"[filter_labels(""points"", (F(""label"") == ""Sky"") & (F(""estimated_yes_no"") == ""yes""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,keypoint,,,,,,,,,,,,,,,,,
get the images with segmentation masks,"[match(F(""segmentations"").exists())]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
any samples that might have a missing prediction,"[match(F(""possible_missing"") > 0)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
samples with at least two missing preds,"[match(F(""possible_missing"") >= 2)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
show me the images with the most missing detections,"[sort_by(""possible_missing"", reverse = True)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
all images with a potentially spurious gt label,"[match(F(""possible_spurious"") > 0)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
most false positive predictions,"[sort_by(""EVAL_KEY_fp"", reverse=True)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
dog detections in all images with a bird,"[match(F(""detections.detections.label"").contains([""bird""])), filter_labels(""detections"", F(""label"") == ""dog"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
dinner time images with a pizza,"[sort_by_similarity(""family eating dinner"", k = 100, brain_key='TEXT_SIM_KEY'), match(F(""ground_truth.detections.label"").contains(""pizza""))]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
images classified as '3',"[match(F(""predicted_number.label"") == '3')]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
samples predicted as blue or green,"[match(F(""prediction.label"").is_in(['blue', 'green']))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
retrieve any samples classified as a basketball by model1 and as a baseball by model2,"[match(F(""model1.label"") == 'basketball'), match(F(""model2.label"") == 'baseball')]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
a random selection of samples that were predicted as 'building' by modelA or modelB ,"[match((F(""modelA.label"") == ""building"") | (F(""modelB.label"") == ""building"")), take(20)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
give me the most unique images with at least 4 false negatives,"[match(F(""EVAL_KEY_fn"") >= 4), sort_by(""uniqueness"", reverse = True), limit(10)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
images with <5 FPs and >=3 FNs for model1,"[match(F(""EVAL_KEY_fp"") < 5), match(F(""EVAL_KEY_fp"") >= 3)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
just show the false pos preds,"[filter_labels(""preds"", F(""EVAL_KEY"") == 'fp')]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
only display the bounding boxes for objects incorrectly predicted to be planets,"[filter_labels(""predictions"", F(""EVAL_KEY"") == 'fp'), filter_labels(""predictions"", F(""label"") == 'Planet')]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
It's too crowded. I only want to see the first 10 objects in gt or pd field,"[limit_labels(""gt"", 10), limit_labels(""pd"", 10)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
show me similar samples to my currently selected images,"[sort_by_similarity(session.selected, k = 25, brain_key='IMAGE_SIM_KEY')]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
map dog to DOG for gt detections,"[map_labels('ground_truth', LEFTBRACKET'dog': 'DOG'RIGHTBRACKET)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"map ""sky"" and ""ground"" to ""background"" for all detections","[map_labels('ground_truth', LEFTBRACKET'sky': 'background', 'ground':'background'RIGHTBRACKET), map_labels('predictions', LEFTBRACKET'sky': 'background', 'ground':'background'RIGHTBRACKET)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
give me all images whose predictions have at least one dining table and at least 3 detections ,"[match((F(""det_model.detections.label"").contains(""dining table""))), match(F(""det_model.detections"").length() > 2)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
show me the samples with at least 4 predicted detections and 2 ground truth detections,"[match((F(""predictions.detections"").length() > 4)), match(F(""ground_truth.detections"").length() > 2)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
"any image with at least 4 ground truth detections, but just the people in these images","[match((F(""ground_truth.detections"").length() > 4)), filter_labels(""ground_truth"", F(""label"") == ""person"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
just the images where modelA and modelB both predict at least 1 salamander,"[match((F(""modelA.detections.label"").contains(""salamander""))), match((F(""modelB.detections.label"").contains(""salamander"")))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
map animal class names for yolov8 field from lowercase to capital-case,"[map_labels('yolob8', LEFTBRACKET'zebra': 'Zebra', 'lion':'Lion', 'giraffe':'Giraffe', 'gorilla':'Gorilla'RIGHTBRACKET)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
only the high confidence predictions in images that have just cats and dogs,"[match(F(""gt.detections.label"").is_subset([""cat"", ""dog""])), filter_field(""predictions"", F(""detections.confidence"") > 0.9)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
images that do not only contain elephants,"[match(~F(""ground_truth.detections.label"").is_subset([""Elephant""]))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
samples of digits 1 and 3,"[match(F(""cls_gt.label"").is_in([""1"", ""3""]))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
show me the images classified as anything except 'night',"[match(F(""classification.label"") != ""night"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
i just want the images that only have popcorn predictions,"[match(F(""pred.detections.label"").is_subset([""popcorn""])).match(F(""pred.detections"").length() > 0)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
all images with at least 10 cars and 5 bike predictions,"[match(F(""model.detections"").filter(F(""label"") == ""Car"").length() >= 10), match(F(""model.detections"").filter(F(""label"") == ""Bicycle"").length() >= 5)]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
just show the Detection labels,"[select_fields([""gt_det"", ""pred_det""])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
hide all the fields that aren't the keypoint labels,"[select_fields([""points""])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
exclude all of the label fields,"[exclude_fields([""detections"", ""classifications"", ""points"", ""segmentation""])]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
just show me the polylines without a label,"[filter_labels(""polylines"", ~F(""label""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
filter the polylines to only the ones that have confidence scores,"[filter_labels(""polylines"", F(""confidence""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me some images with a Fork or a Knife detected,"[match(F(""ground_truth.detections.label"").contains([""Fork"",""Train""]))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
any scene that resembles a birthday party,"[sort_by_similarity('birthday party', k = 25, brain_key = 'TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
images with a water buffalo in them,"[sort_by_similarity('water buffalo', brain_key = 'TEXT_SIM_KEY', k = 30)]",Eric,Image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me samples that have a tricycle,"[sort_by_similarity('tricycle', k = 30, brain_key='TEXT_SIM_KEY')]",Eric,Image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
what images contain a reptile?,"[sort_by_similarity('reptile', brain_key = 'TEXT_SIM_KEY', k=25)]",Eric,Image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
where are my turning lanes?,"[sort_by_similarity('turning lane', brain_key = 'TEXT_SIM_KEY', k = 100)]",Eric,Image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me images with llamas,"[sort_by_similarity('llama', brain_key='TEXT_SIM_KEY', k = 200)]",Eric,Image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"sorty images by how similar they are to a classroom, and show me the top 10","[sort_by_similarity('a classroom', k=10, brain_key='TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"100 images that resemble a Gameboy Advance, with distances, evaluated with 'pinecone' key","[sort_by_similarity('a Game Boy Advance', k=100, brain_key='TEXT_SIM_KEY', dist_field = True)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
3 images that look the most like sample with ID uigweuyf,"[sort_by_similarity('uigweuyf', k=3, brain_key='IMAGE_SIM_KEY')]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me the 13 most similar images to the 4th image,"[sort_by_similarity(dataset.skip(3).first().id, k=13, brain_key='IMAGE_SIM_KEY')]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"sort by similarity to the last image with a table, with key 'text_sim'","[sort_by_similarity(dataset.match(F('ground_truth.detections.label').contains('table')).last().id, brain_key='IMAGE_SIM_KEY']",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
sort the samples with a car prediction by how gloomy the scene is,"[match(F('pred.detections.label').contains('Car')), sort_by_similarity('gloomy', k = 25, brain_key='TEXT_SIM_KEY')]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
take the images of buildings and find the ones that are most run down,"[match(F('classif.label') =='Building'), sort_by_similarity('run down', k = 10, brain_key='TEXT_SIM_KEY')]",Jacob,image,FALSE,FALSE,TRUE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
get 50 random samples and find the one that is brightest,"[take(50), sort_by_similarity('bright', k = 50, brain_key = 'TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
I want to see the bluest images,"[sort_by_similarity('blue', k = 25, brain_key = 'TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
10 images with a lot of green or grass,"[sort_by_similarity('green and grassy', k = 10, brain_key = 'TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
show me all images with food,"[match(F(""ground_truth.detections.label"").contains([""apple"",""banana"",""broccoli"",""cake"",""carrot"",""donut"",""hot dog"",""orange"",""pizza"",""sandwich""]))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
images with only household objects,"[match(F(""ground_truth.detections.label"").is_subset([""knife"",""fork"",""dining table"",""scissors"",""door"",""sink"",""chair"", ""plate"",""lamp"",""desk""]))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
patches for bikes and bike-related gear,"[filter_labels(""ground_truth"", F(""label"").is_in(['Bicycle', 'Bicycle helmet', 'Bicycle wheel'])), to_patches(""ground_truth"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
filter for detections of junk food,"[filter_labels(""ground_truth"", F(""label"").is_in([""Ice cream"", ""Hamburger"", ""French fries"", ""Dessert"", ""Cookie"", ""Candy"", ""Baked goods""]))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
all utensil patches in any image with a plate or a bowl,"[match(F(""ground_truth.detections.label"").contains([""Plate"", ""Bowl""])), filter_labels(""ground_truth"", F(""label"").is_in([""Fork"", ""Spoon"", ""Knife"", 'Chopsticks'])), to_patches(""ground_truth"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
show me the object patches for the 10 images with the most objects,"[sort_by(F(""detections.detections"").length(), reverse=True), limit(10), to_patches(""detections"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
"find the 10 objects that most fit ""musical instrument""","[to_patches(""detections""), sort_by_similarity(""musical instrument"", k = 10, brain_key='TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
get the 3 prediction patches that look most like a kitchen table,"[to_patches(""pred"").sort_by_similarity(""kitchen table"", k = 3, brain_key='TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
find the 5 men who look most like they could be personal trainers,"[filter_labels(""detections"", F(""label"") == ""Man""), to_patches(""detections""), sort_by_similarity(""personal trainer"", k = 5, brain_key='TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
"retrieve the 20 detections from model A that are the cutest puppies, with similarity computed with my_sim_key","[to_patches(""modelA_det""), sort_by_similarity(""cute puppy"", k = 20, brain_key='TEXT_SIM_KEY')]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
patches for large objects in gt detections field,"[filter_labels(""gt"", F(""bounding_box"")[2] * F(""bounding_box"")[3] > 0.8).to_patches(""gt"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
isolate the small car predictions,"[filter_labels(""pred"", F(""bounding_box"")[2] * F(""bounding_box"")[3] < 0.2), filter_labels(""pred"", F(""label"") == ""Car""), to_patches(""pred"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
Show me evaluation patches,"[to_evaluation_patches(""EVAL_KEY"")]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Display the evaluation patches for the first images in the dataset,"[limit(1), to_evaluation_patches(""EVAL_KEY"")]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Eval patches for model1,"[to_evaluation_patches(""EVAL_KEY"")]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
show all TP predictions,"[to_evaluation_patches(""EVAL_KEY""), match(F(""type"") == ""tp"")]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Any object detections that were wrong,"[to_evaluation_patches(""EVAL_KEY""), match(F(""type"").is_in([""fp"",""fn""]))]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Retrieve the detection predictions with IoU > 80%,"[to_evaluation_patches(""EVAL_KEY""), match(F(""iou"") > 0.8)]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Show me the evaluation patches sorted by IoU,"[to_evaluation_patches(""EVAL_KEY""), sort_by(""iou"")]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Just show me false positive predictions,"[filter_labels(""predictions"", F(""EVAL_KEY"") == ""fp"")]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Give me 10 random images with a false positive prediction,"[match(F(""EVAL_KEY_fp"")>0), take(10)]",Jacob,image,FALSE,FALSE,FALSE,TRUE,FALSE,all,,,,,,,,,,,,,,,,,
Images with llamas,"[match(F(""ground_truth.detections.label"").contains(""llama""))]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,detection,,,,,,,,,,,,,,,,,
cats,"[match(F(""ground_truth.label"") == ""Cat"")]",Jacob,image,FALSE,FALSE,FALSE,FALSE,FALSE,classification,,,,,,,,,,,,,,,,,
Samples whose image is less than 48 KB,[match(F('metadata.size_bytes') < 48 * 1024)],Jacob,image,FALSE,FALSE,FALSE,FALSE,TRUE,all,,,,,,,,,,,,,,,,,
show me the 10 haziest images,"[sort_by_similarity(""hazy"", brain_key = ""TEXT_SIM_KEY"", k = 10)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
photos that look like they were taken in the woods,"[sort_by_similarity(""the woods"", brain_key = ""TEXT_SIM_KEY"", k = 25)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
50 blurry images,"[sort_by_similarity(""blurry"", brain_key = ""TEXT_SIM_KEY"", k = 50)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
an elizabethan estate,"[sort_by_similarity(""Elizabethan estate"", brain_key = ""TEXT_SIM_KEY"", k = 25)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
retrieve the images that are similar to a rubber duck,"[sort_by_similarity(""Rubber duck"", brain_key = ""TEXT_SIM_KEY"", k = 25)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
"get the 100 images that look most like they come from an animated film, and shuffle them","[sort_by_similarity(""Animation"", brain_key = ""TEXT_SIM_KEY"", k = 100)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
samples that look really crowded,"[sort_by_similarity(""A crowded scene"", brain_key = ""TEXT_SIM_KEY"", k = 25)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,
A grassy knoll,"[sort_by_similarity(""A grassy knoll"", brain_key = ""TEXT_SIM_KEY"", k = 25)]",Jacob,image,FALSE,TRUE,FALSE,FALSE,FALSE,all,,,,,,,,,,,,,,,,,